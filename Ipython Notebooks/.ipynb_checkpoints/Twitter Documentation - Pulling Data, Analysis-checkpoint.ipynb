{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling Twitter Historical Data, Feb 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello World! This was created on Feb 22, 2019.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, progress shall be documented for work on integrating Twitter tweet counts with predictive gambling. Aim is to find:\n",
    "\n",
    "1. Undervalued opportunities that will correct itself\n",
    "2. Near-certain swings that will occur\n",
    "3. Calculate risk \"theta decay\" and negative risk options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, working outlines of these things are ready: 2/22/2019:\n",
    "\n",
    "1. Market data pulling script \"__Base3.py__\"\n",
    "\n",
    "Abilty to save historical data to pickle.\n",
    "\n",
    "2. Twitter Live count - \"__Twitterlive.py__\"\n",
    "\n",
    "Notify when a new tweet has occured. Implemented sound on Linux.\n",
    "\n",
    "3. Twitter historical data pull \"__Twitter RDT r1.py__\"\n",
    "\n",
    "Weird problem occurred today with pulling Realdonaldtrump handle, only doing 1/20/80 instead of full history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation: Twitter RDT r1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminaries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import tweepy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#consumer_key, consumer_secret on account APythonTesting1, password.\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "handle = \"realDonaldTrump\"\n",
    "User = api.get_user(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Save and Load functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Not implemented in a class! For classes make sure to add _self_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def picklesave(l, filename = \"Pickle.p\"):\n",
    "    \"\"\"Save to pickle file for reference\"\"\"\n",
    "    with open(filename, \"wb\") as fp:\n",
    "        pickle.dump(l, fp)\n",
    "    \n",
    "def pickleread(filename = \"Pickle.p\"):\n",
    "    \"\"\"Read from pickle file\"\"\"\n",
    "    r = pickle.load(open(filename, \"rb\"))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading tweets and extracting time from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def htweet():\n",
    "    \"\"\"Get maximum 3200 tweets from twitter. Return as list with type Status\"\"\"\n",
    "    alltweets = []\n",
    "    for tweet in tweepy.Cursor(api.user_timeline,id=handle).items():\n",
    "        alltweets.append(tweet)\n",
    "    return alltweets\n",
    "\n",
    "def extractdt(l):\n",
    "    \"\"\"Extract datetime list from htweet list, return as list. Time in EST\"\"\"\n",
    "    dt = []\n",
    "    for i in l:\n",
    "        obj = i.created_at\n",
    "        EST = obj - timedelta(hours=5)\n",
    "        dt.append(EST)\n",
    "    return dt\n",
    "\n",
    "def pullplot():\n",
    "    \"\"\"Get historical tweets, extract date\"\"\"\n",
    "    m = htweet()\n",
    "    k = extractdt(m)\n",
    "    k.sort()\n",
    "    return k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: For PST, change line to PST = obj - timedelta(hours=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__pullplot()__ returns a list of _datetime_ objects.\n",
    "\n",
    "More methods: Specialized functions for datetime to return date only, time only, time and fraction of an hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract time data from Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateonly(l):\n",
    "    \"\"\"Make datetime list a date-only list\"\"\"\n",
    "    d = []\n",
    "    for i in l:\n",
    "        d.append(i.date())\n",
    "    return d\n",
    "        \n",
    "def timeonly(l):\n",
    "    \"\"\"Make datetime list a time-only list\"\"\"\n",
    "    t = []\n",
    "    for i in l:\n",
    "        t.append(i.time())\n",
    "    return t\n",
    "    \n",
    "def timeonlydot(l):\n",
    "    \"\"\"Make datetime list format in range 0.0 to 24\n",
    "    ex. 16:32am = 16.5333...\"\"\"\n",
    "    hourstore = []\n",
    "    for i in l:\n",
    "        hourstore.append(i.hour + i.minute / 60)\n",
    "    \n",
    "    return hourstore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Datetime objects by Date or Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separatebydate(l):\n",
    "    \"\"\"From data, separate by day of the week\"\"\"\n",
    "    container = [0] * 7\n",
    "    for i in l:\n",
    "        index = i.weekday()\n",
    "        container[index] += 1\n",
    "    \n",
    "    return container\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wednesdaycount(l):\n",
    "    \"\"\"From data, count number of tweets in each wednesday period.\"\"\"\n",
    "    container = []\n",
    "    \n",
    "    init = l[0] + timedelta(days=( (9 - (l[0].weekday()) % 7) )) # first Wednesday after @ 12pm ET\n",
    "    init = init.replace(hour=12, minute=0, second = 0)\n",
    "\n",
    "    start = init\n",
    "    counter = 0\n",
    "    for i in range(len(l)):\n",
    "        if l[i] < start:\n",
    "            counter += 1\n",
    "        else:\n",
    "            container.append(counter)\n",
    "            counter = 0\n",
    "            start = start + timedelta(days=7)\n",
    "    container.append(counter)\n",
    "    \n",
    "    del container[0] #not full\n",
    "    return container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separatewednesday(l):\n",
    "    \"\"\"From data, separate into separate wednesday buckets.\"\"\"\n",
    "    container = []\n",
    "    \n",
    "    init = l[0] + timedelta(days=( (9 - (l[0].weekday()) % 7) )) + timedelta( # first Wednesday after @ 12pm ET\n",
    "    init = init.replace(hour=12, minute=0, second = 0) # figure out the exact later\n",
    "    \n",
    "    #assuming doesn't start ON that Wednesday AFTERNOON fix it later with time. Discard first one anyway.\n",
    "\n",
    "    start = init\n",
    "    counter = []\n",
    "    for i in range(len(l)):\n",
    "        if l[i] < start:\n",
    "            counter.append(l[i])\n",
    "        else:\n",
    "            container.append(counter)\n",
    "            counter = []\n",
    "            start = start + timedelta(days=7)\n",
    "    container.append(counter)\n",
    "    \n",
    "    del container[0] #not full\n",
    "    \n",
    "    return container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__separatewednesday__ is a breakthrough in data segregation. Now all the data is sorted into single week periods by Wednesdays.\n",
    "@Realdonaldtrump markets are Wednesdays.\n",
    "\n",
    "Note: container[0] is, in general, an unsaturated list. If data BEGINS on WED MORNING, those dates will be included in container[0] even though they are not part of that period.\n",
    "If data BEGINS on WED AFTERNOON, then some may be left out. To prevent problems, that whole week is unconsidered by only starting from the NEXT WEDNESDAY.\n",
    "\n",
    "The very last container is the current counter. 2/22/19: Use twitter to confirm by mousing over the \"tweet\" count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns\n",
    "[ \n",
    "[datetime... datetime] # One week\n",
    "...\n",
    "[datetime... datetime] # Another week\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generalized Form__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separatebyweekday(l, weekday = 0):\n",
    "    \"\"\"From data, separate into buckets by week. Specify weekday: 0 for Monday, 6 for Sunday. End time always 12pm (EST).\"\"\"\n",
    "    container = []\n",
    "    \n",
    "    init = l[0] + timedelta(days=( ((7 + weekday) - (l[0].weekday()) % 7) )) # first @ 12pm ET. If on the day, start from the next week for consistency.\n",
    "    init = init.replace(hour=12, minute=0, second = 0)\n",
    "\n",
    "    start = init\n",
    "    counter = []\n",
    "    for i in range(len(l)):\n",
    "        if l[i] < start:\n",
    "            counter.append(l[i])\n",
    "        else:\n",
    "            container.append(counter)\n",
    "            counter = []\n",
    "            start = start + timedelta(days=7)\n",
    "    container.append(counter)\n",
    "    \n",
    "    del container[0] #not full\n",
    "    \n",
    "    return container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results\n",
    "\n",
    "Use on parsed data only. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specialized functions: plotit, plotit2, plotit3.\n",
    "    \n",
    "* plotit plots as a basic __step__ graph.\n",
    "* plotit2 plots dots only.\n",
    "* plotit3 plots with y-axis (Tweet count) scale = n, default 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotit(list):\n",
    "    \"\"\"Plot... reverses x and y axis\"\"\"\n",
    "    list.sort() #always make sure sorted?\n",
    "    x = np.asarray(list)\n",
    "    y = np.arange(len(list))\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.xlabel(\"Time (Wednesday 12pm to Wednesday 12pm)\")\n",
    "    plt.ylabel(\"Tweet count\")\n",
    "    plt.step(x, y)\n",
    "    for label in ax.get_xticklabels()[::2]:\n",
    "        label.set_visible(False)\n",
    "\n",
    "def plotit2(list):\n",
    "    \"\"\"Plot function... reverses x and y axis\"\"\"\n",
    "    list.sort() #always make sure sorted?\n",
    "    x = np.asarray(list)\n",
    "    y = np.arange(len(list))\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.xlabel(\"Time (Wed to Wed 12pm)\")\n",
    "    plt.ylabel(\"Tweet count\")\n",
    "    plt.plot(x, y, 'b.')\n",
    "    for label in ax.get_xticklabels()[::2]:\n",
    "        label.set_visible(False)\n",
    "        \n",
    "        \n",
    "\n",
    "def plotit3(list, n = 100):\n",
    "    \"\"\"Plot function... reverses x and y axis. Limits each to the top.\"\"\"\n",
    "    list.sort() #always make sure sorted?\n",
    "    x = np.asarray(list)\n",
    "    y = np.arange(len(list))\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.ylim(top = n)\n",
    "    \n",
    "    plt.xlabel(\"Time (Wed to Wed 12pm)\")\n",
    "    plt.ylabel(\"Tweet count\")\n",
    "    plt.plot(x, y, 'b.')\n",
    "    for label in ax.get_xticklabels()[::2]:\n",
    "        label.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(l):\n",
    "    \"\"\"Start operation on a preparsed list\"\"\"\n",
    "    for i in range(len(l)):\n",
    "        plotit(l[i])\n",
    "        num = \"Plot \"+ str(i) + \".svg\"\n",
    "        plt.savefig(num, format = 'svg', dpi=1200)\n",
    "        plt.show()\n",
    "        input(\"This is plot number \" + str(i) + \".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__start__ plots and saves each into directory, showing output for each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraneous Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barplot(input, bins = 23):\n",
    "    \"\"\"Input: hours objects. Goal: frequency of each time.\n",
    "    Use multiples of 24, minus 1\"\"\"\n",
    "    plt.hist(input, bins = bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deltatime(data):\n",
    "    \"\"\"From datatime list return the time between each tweet\"\"\"\n",
    "    deltastore = []\n",
    "    for i in range((len(data)) - 1):\n",
    "        a = data[i+1] - data[i] #timedelta object\n",
    "        deltastore.append(a.total_seconds())\n",
    "    \n",
    "    return deltastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that concludes the current progress on the Twitter Pull.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
